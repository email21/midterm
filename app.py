import streamlit as st
from langchain_upstage import ChatUpstage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from dotenv import load_dotenv
import os

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
api_key = os.getenv("SOLAR_API_KEY")

if "messages" not in st.session_state:
    st.session_state.messages = []  # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

def reset_chat():
    """ëŒ€í™” ë‚´ìš©ì„ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜"""
    st.session_state.messages.clear()
    st.rerun()

# Streamlit í˜ì´ì§€
st.title("ğŸ’  Solar LLM Chatbot ")
st.write("ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ëŠ” ê¸°ë³¸ ì±—ë´‡ì…ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°”ì— ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
with st.sidebar:
    st.header("ì˜µì…˜")
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        reset_chat()

# ì±— ëª¨ë¸ ì´ˆê¸°í™”
try:
    chat_model = ChatUpstage(upstage_api_key=api_key)
except Exception as e:
    st.error(f"API í‚¤ ì˜¤ë¥˜: {e}")
    st.stop()

# ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
system_template = """ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì™€ì˜ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ì¼ê´€ì„± ìˆëŠ” ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”.
í•­ìƒ ì •ì¤‘í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„± (ì´ì „ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨)
prompt_template = ChatPromptTemplate.from_messages([
    ("system", system_template),
    MessagesPlaceholder("chat_history"),  # ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ë“¤ì–´ê°ˆ ìë¦¬
    ("human", "{input}")  # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
])

# ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ LangChain ë©”ì‹œì§€ í˜•íƒœë¡œ ë³€í™˜
        chat_history = []
        for msg in st.session_state.messages[:-1]:  # í˜„ì¬ ë©”ì‹œì§€ ì œì™¸
            if msg["role"] == "user":
                chat_history.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                chat_history.append(AIMessage(content=msg["content"]))
        
        try:
            # í”„ë¡¬í”„íŠ¸ì— í˜„ì¬ ì…ë ¥ê³¼ ëŒ€í™” ê¸°ë¡ ì „ë‹¬
            messages = prompt_template.format_messages(
                chat_history=chat_history,
                input=user_input
            )
            
            # AI ëª¨ë¸ë¡œë¶€í„° ì‘ë‹µ ìƒì„±
            response = chat_model.invoke(messages)
            ai_response = response.content
            
            # ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œ
            message_placeholder.markdown(ai_response)
            
            # AI ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
            
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")